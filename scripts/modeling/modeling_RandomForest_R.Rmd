---
title: "Random Forest"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE, eval=TRUE, message=F, include=T,comment=NULL,fig.width = 5, warning = FALSE, fig.height = 3,tidy.opts=list(width.cutoff=50),tidy=TRUE,cache = TRUE)
```

```{r packageCheck, include=FALSE}
mypacks <- c("ggplot2","stringr","dplyr","knitr","lubridate","car","tidyr","cvTools","rpart","nnet","gbm","yaImpute","randomForest")  # what packages are needed?
packs <- installed.packages()   # find installed package list
install.me <- mypacks[!(mypacks %in% packs[,"Package"])]  #what needs to be installed?
if (length(install.me) >= 1) install.packages(install.me, repos = "http://cran.us.r-project.org")   # install (if needed)
lapply(mypacks, library, character.only=TRUE)  # load all packages
```

# A function to determine cv in partition
```{r}
CVInd <- function(n,K) { #n is sample size; K is number of parts; returns   K-length list of indices for each part
  m<-floor(n/K) #approximate size of each part
  r<-n-m*K
  I<-sample(n,n) #random reordering of the indices
  Ind<-list() #will be list of indices for all K parts
  length(Ind)<-K
  for (k in 1:K) {
    if (k <= r) kpart <- ((m+1)*(k-1)+1):((m+1)*k)
    else kpart<-((m+1)*r+m*(k-r-1)+1):((m+1)*r+m*(k-r))
    Ind[[k]] <- I[kpart] #indices for kth part of data
  }
Ind
}
```

# Read data
```{r}
train <- read.csv("training_imputed_r_mice_v1.csv")
test <- read.csv("test_imputed_r_mice_v1.csv")
```

# Manipulate variables
```{r}
train_df <- train %>%
  select(-id, -contains("encoded"))

train_df[sapply(train_df, is.character)] <- lapply(train_df[sapply(train_df, is.character)], as.factor)

sapply(train_df, class) 
train_df$public_meeting_new <- as.factor(train_df$public_meeting_new)
train_df$permit_new <- as.factor(train_df$permit_new)

test_df <- test %>%
  select(-id, -contains("encoded"))

test_df[sapply(test_df, is.character)] <- lapply(test_df[sapply(test_df, is.character)], as.factor)

sapply(test_df, class) 
test_df$public_meeting_new <- as.factor(test_df$public_meeting_new)
test_df$permit_new <- as.factor(test_df$permit_new)

# use common levels for rf
common <- intersect(names(train_df), names(test_df)) 
for (p in common) { 
  if (class(train_df[[p]]) == "factor") { 
    levels(test_df[[p]]) <- levels(train_df[[p]]) 
  } 
}
```

# check some quality
```{r}
sum(is.na(train_df))
train_df[is.na(train_df),]
```

# find the best random Forest model
```{r}
Sys.time()
## try out different mtrys and node sizes (with ntree=300)

## Round 1: (5,5) gives best result with ccr 0.816
# mtrys <- c(1,3,5,7,9,11,13,15)
# nsizes <- c(1,3,5,7,9,11,13,15)

## Round 2 (to be done)
mtrys <- c(4,5,6)
nsizes <- c(3:15)

cur_best_mtry <- -1
cur_best_nsize <- -1
cur_best_ccr <- -99999
all_ccr <- c()

for (nsize in nsizes){
  for (mt in mtrys){
    set.seed(1)
    rForest_1 <- randomForest(status_group~., 
                            data=train_df, mtry=mt, 
                            ntree = 500,nodesize = nsize, 
                            importance = TRUE) 
    
    oob_ccr <- sum(diag(rForest_1$confusion))/sum(rForest_1$confusion)
    all_ccr <- c(all_ccr,oob_ccr) # all ccr
    if (oob_ccr > cur_best_ccr){
      cur_best_mtry <- mt
      cur_best_nsize <- nsize
      cur_best_ccr <- oob_ccr
    }
  }
}

# best parameters
rf_best_mtry <- cur_best_mtry
rf_best_mtry
rf_best_nsize <- cur_best_nsize
rf_best_nsize

# best ccr result
rf_best_ccr <- cur_best_ccr
rf_best_ccr

# all ccr results
all_ccr

Sys.time()
```

# get max
```{r}
max(all_ccr)
which(all_ccr == max(all_ccr)) # 19th..ccr=0.816 (5,5) gets us best ccr for round 1

```


# try to get a prediction
```{r}
set.seed(1)
rForest_best <- randomForest(status_group~., 
                        data=train_df, mtry = 5, 
                        ntree = 500,nodesize = 5, 
                        importance = TRUE) 

sum(diag(rForest_best$confusion))/sum(rForest_best$confusion)
```

# predict
```{r}
output <- test %>% 
  mutate(status_group = predict(rForest_best, test_df)) %>%
  select(id, status_group)

write.csv(output,"out_r_v2.csv",row.names=FALSE)

```